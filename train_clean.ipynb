{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries \n",
    "\n",
    "#required libraries for detectron2\n",
    "#PyTorch â‰¥ 1.5 and torchvision that matches the PyTorch installation. You can install them together at pytorch.org to make sure of this\n",
    "#!pip install torchvision\n",
    "#OpenCV is optional and needed by demo and visualization\n",
    "#!pip install opencv-python\n",
    "#This will only work on Linux or macOS\n",
    "####if Detectron2 is missing:\n",
    "#!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set here your variables\n",
    "\n",
    "#train: Annotated Images for training\n",
    "#train.json: Annotations + Path to Images for all images stored in train\n",
    "#test: Annotated Images for model evaluation (Taken from train)\n",
    "#test.json: Like train.json but for test\n",
    "#test_set2: Unannotated images which do not stem from the train data to evaluate generalization of the model\n",
    "\n",
    "#please ensure the following structure:\n",
    "# |\n",
    "# |-working directory\n",
    "#     |-train\n",
    "#     |   |-img1.jpg\n",
    "#     |   |-img2.jpg\n",
    "#     |   |-[...]\n",
    "#     |   |-train.json\n",
    "#     |\n",
    "#     |-test\n",
    "#     |   |-img1.jpg\n",
    "#     |   |-img2.jpg\n",
    "#     |   |-[...]\n",
    "#     |   |-test.json\n",
    "#     |\n",
    "#     |-test_set2\n",
    "#         |-img1.jpg\n",
    "#         |-img2.jpg\n",
    "#         |-[...]\n",
    "\n",
    "#working directory \n",
    "working_dir=\"/home/leto/Training_C_AI_DATA/k_means\"\n",
    "#Save Model Weights to\n",
    "output_dir_model=\"/home/leto/Training_C_AI_DATA/k_means/1000\"\n",
    "#save pictures with prediction\n",
    "output_dir_imgs=\"/home/leto/Training_C_AI_DATA/k_means/1000\"\n",
    "############################################\n",
    "####OPTIMIZE HERE FOR BETTER PERFORMANCE####\n",
    "#Iterations for training\n",
    "training_iterations=1000\n",
    "#Number of workers\n",
    "worker_num=2\n",
    "#Images per Batch (a higher number will need more VRAM, but is also good for stability in the learning process)\n",
    "batchsize=2\n",
    "#Base learning rate\n",
    "base_lr=0.00025\n",
    "#Number of classes (always +1 bc of background)\n",
    "num_classes=10\n",
    "#detection threshold (threshold for a class probability upon which a prediction will be considered to be true)\n",
    "detect_thresh=0.55\n",
    "#if test_set2 was renamed\n",
    "test_set2=\"test_set2\"\n",
    "\n",
    "\n",
    "#####DO NOT CHANGE#####\n",
    "train_dir=os.path.join(working_dir,\"train\")\n",
    "train_json=\"train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dataset 'train' is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-981115b72d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimgs_anns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36mregister_coco_instances\u001b[0;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;31m# 1. register a function which returns dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m     \u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_coco_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;31m# 2. Optionally, add metadata about this dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/detectron2/data/catalog.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, name, func)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[1;32m     36\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You must register a function with `DatasetCatalog.register`!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is already registered!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataset 'train' is already registered!"
     ]
    }
   ],
   "source": [
    "json_train_file = os.path.join(working_dir, \"train\", train_json)\n",
    "#load dataset and create coco dataset for DETECTRON2\n",
    "with open(json_train_file) as f:\n",
    "    imgs_anns = json.load(f)\n",
    "\n",
    "register_coco_instances(\"train\", {}, os.path.join(working_dir,\"train\",\"train.json\"), \"train\")\n",
    "register_coco_instances(\"test\", {}, os.path.join(working_dir,\"test\",\"test.json\"), \"test\")\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"train\")\n",
    "dataset_metadata = MetadataCatalog.get(\"train\")\n",
    "\n",
    "#a warning about the category ids will appear - this is okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the config file for training\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = worker_num\n",
    "cfg.OUTPUT_DIR = output_dir_model\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = batchsize\n",
    "cfg.SOLVER.BASE_LR = base_lr # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = training_iterations\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n",
    "cfg.nms = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 15:46:51 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/30 15:46:51 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[11/30 15:46:51 d2.data.datasets.coco]: \u001b[0mLoaded 523 images in COCO format from /data/collembola_ai/train/train.json\n",
      "\u001b[32m[11/30 15:46:51 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 521 images left.\n",
      "\u001b[32m[11/30 15:46:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[11/30 15:46:51 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[11/30 15:46:51 d2.data.common]: \u001b[0mSerializing 521 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 15:46:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.22 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/30 15:46:51 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[11/30 15:47:01 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 19  total_loss: 3.404  loss_cls: 2.647  loss_box_reg: 0.66  loss_rpn_cls: 0.04355  loss_rpn_loc: 0.04445  time: 0.5098  data_time: 0.3318  lr: 4.9953e-06  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:47:12 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 39  total_loss: 3.343  loss_cls: 2.501  loss_box_reg: 0.7033  loss_rpn_cls: 0.08192  loss_rpn_loc: 0.0477  time: 0.5171  data_time: 0.3405  lr: 9.9902e-06  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:47:22 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 59  total_loss: 2.986  loss_cls: 2.248  loss_box_reg: 0.6379  loss_rpn_cls: 0.03773  loss_rpn_loc: 0.04215  time: 0.5212  data_time: 0.3468  lr: 1.4985e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:47:33 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 79  total_loss: 2.541  loss_cls: 1.88  loss_box_reg: 0.5524  loss_rpn_cls: 0.01858  loss_rpn_loc: 0.02505  time: 0.5235  data_time: 0.3465  lr: 1.998e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:47:43 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 99  total_loss: 2.194  loss_cls: 1.474  loss_box_reg: 0.61  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.03247  time: 0.5236  data_time: 0.3394  lr: 2.4975e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:47:54 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 119  total_loss: 1.667  loss_cls: 1.023  loss_box_reg: 0.6493  loss_rpn_cls: 0.03246  loss_rpn_loc: 0.02551  time: 0.5219  data_time: 0.3263  lr: 2.997e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:48:04 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 139  total_loss: 1.445  loss_cls: 0.7679  loss_box_reg: 0.6067  loss_rpn_cls: 0.02777  loss_rpn_loc: 0.03705  time: 0.5207  data_time: 0.3251  lr: 3.4965e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:48:15 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 159  total_loss: 1.319  loss_cls: 0.6807  loss_box_reg: 0.5842  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.03736  time: 0.5213  data_time: 0.3466  lr: 3.996e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:48:25 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 179  total_loss: 1.633  loss_cls: 0.8051  loss_box_reg: 0.7291  loss_rpn_cls: 0.0273  loss_rpn_loc: 0.03104  time: 0.5230  data_time: 0.3505  lr: 4.4955e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:48:36 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 199  total_loss: 1.674  loss_cls: 0.8444  loss_box_reg: 0.7446  loss_rpn_cls: 0.02385  loss_rpn_loc: 0.04058  time: 0.5228  data_time: 0.3280  lr: 4.995e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:48:46 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 219  total_loss: 1.552  loss_cls: 0.7677  loss_box_reg: 0.7039  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.03018  time: 0.5230  data_time: 0.3424  lr: 5.4945e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:48:56 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 239  total_loss: 1.221  loss_cls: 0.592  loss_box_reg: 0.5601  loss_rpn_cls: 0.01377  loss_rpn_loc: 0.0201  time: 0.5217  data_time: 0.3315  lr: 5.994e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:49:07 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 259  total_loss: 1.332  loss_cls: 0.6879  loss_box_reg: 0.6108  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.02527  time: 0.5236  data_time: 0.3639  lr: 6.4935e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:49:18 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 279  total_loss: 1.442  loss_cls: 0.6797  loss_box_reg: 0.7254  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.02647  time: 0.5230  data_time: 0.3261  lr: 6.993e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:49:29 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 299  total_loss: 1.322  loss_cls: 0.653  loss_box_reg: 0.6409  loss_rpn_cls: 0.009009  loss_rpn_loc: 0.0236  time: 0.5239  data_time: 0.3523  lr: 7.4925e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:49:39 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 319  total_loss: 1.232  loss_cls: 0.5863  loss_box_reg: 0.6006  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.01889  time: 0.5228  data_time: 0.3268  lr: 7.992e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:49:49 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 339  total_loss: 1.554  loss_cls: 0.7286  loss_box_reg: 0.7948  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.0315  time: 0.5220  data_time: 0.3321  lr: 8.4915e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:49:59 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 359  total_loss: 1.591  loss_cls: 0.747  loss_box_reg: 0.7572  loss_rpn_cls: 0.008373  loss_rpn_loc: 0.03628  time: 0.5218  data_time: 0.3378  lr: 8.991e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:50:10 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 379  total_loss: 1.376  loss_cls: 0.6451  loss_box_reg: 0.6433  loss_rpn_cls: 0.01591  loss_rpn_loc: 0.0333  time: 0.5214  data_time: 0.3247  lr: 9.4905e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:50:20 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 399  total_loss: 1.222  loss_cls: 0.5823  loss_box_reg: 0.6389  loss_rpn_cls: 0.005066  loss_rpn_loc: 0.02532  time: 0.5209  data_time: 0.3248  lr: 9.99e-05  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:50:31 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 419  total_loss: 1.308  loss_cls: 0.6184  loss_box_reg: 0.648  loss_rpn_cls: 0.005139  loss_rpn_loc: 0.01696  time: 0.5215  data_time: 0.3452  lr: 0.0001049  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:50:41 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 439  total_loss: 1.368  loss_cls: 0.6087  loss_box_reg: 0.6901  loss_rpn_cls: 0.01069  loss_rpn_loc: 0.02728  time: 0.5208  data_time: 0.3161  lr: 0.00010989  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:50:52 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 459  total_loss: 1.456  loss_cls: 0.6303  loss_box_reg: 0.7158  loss_rpn_cls: 0.008298  loss_rpn_loc: 0.01881  time: 0.5215  data_time: 0.3517  lr: 0.00011489  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:51:02 d2.utils.events]: \u001b[0m eta: 0:04:28  iter: 479  total_loss: 1.317  loss_cls: 0.5843  loss_box_reg: 0.7069  loss_rpn_cls: 0.007044  loss_rpn_loc: 0.03018  time: 0.5216  data_time: 0.3398  lr: 0.00011988  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:51:13 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 499  total_loss: 1.289  loss_cls: 0.5757  loss_box_reg: 0.6754  loss_rpn_cls: 0.006323  loss_rpn_loc: 0.0207  time: 0.5217  data_time: 0.3367  lr: 0.00012488  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:51:23 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 519  total_loss: 1.262  loss_cls: 0.5336  loss_box_reg: 0.6009  loss_rpn_cls: 0.00629  loss_rpn_loc: 0.02403  time: 0.5223  data_time: 0.3562  lr: 0.00012987  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:51:34 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 539  total_loss: 1.213  loss_cls: 0.5285  loss_box_reg: 0.6356  loss_rpn_cls: 0.005548  loss_rpn_loc: 0.02017  time: 0.5226  data_time: 0.3391  lr: 0.00013487  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:51:45 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 559  total_loss: 1.157  loss_cls: 0.5057  loss_box_reg: 0.6032  loss_rpn_cls: 0.005451  loss_rpn_loc: 0.0251  time: 0.5229  data_time: 0.3440  lr: 0.00013986  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:51:55 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 579  total_loss: 0.9747  loss_cls: 0.4164  loss_box_reg: 0.5131  loss_rpn_cls: 0.003596  loss_rpn_loc: 0.0201  time: 0.5228  data_time: 0.3418  lr: 0.00014486  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:52:05 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 599  total_loss: 1.064  loss_cls: 0.4609  loss_box_reg: 0.5527  loss_rpn_cls: 0.007663  loss_rpn_loc: 0.0243  time: 0.5224  data_time: 0.3291  lr: 0.00014985  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:52:15 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 619  total_loss: 0.8056  loss_cls: 0.3495  loss_box_reg: 0.429  loss_rpn_cls: 0.007367  loss_rpn_loc: 0.02184  time: 0.5218  data_time: 0.3192  lr: 0.00015485  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:52:26 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 639  total_loss: 1.005  loss_cls: 0.4714  loss_box_reg: 0.5323  loss_rpn_cls: 0.002272  loss_rpn_loc: 0.03329  time: 0.5215  data_time: 0.3356  lr: 0.00015984  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:52:36 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 659  total_loss: 0.9848  loss_cls: 0.4371  loss_box_reg: 0.4896  loss_rpn_cls: 0.007662  loss_rpn_loc: 0.03093  time: 0.5210  data_time: 0.3215  lr: 0.00016484  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:52:46 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 679  total_loss: 0.9368  loss_cls: 0.4457  loss_box_reg: 0.4655  loss_rpn_cls: 0.007509  loss_rpn_loc: 0.02299  time: 0.5206  data_time: 0.3286  lr: 0.00016983  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:52:57 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 699  total_loss: 0.7813  loss_cls: 0.4025  loss_box_reg: 0.361  loss_rpn_cls: 0.005325  loss_rpn_loc: 0.01913  time: 0.5209  data_time: 0.3462  lr: 0.00017483  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:53:07 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 719  total_loss: 1.159  loss_cls: 0.4796  loss_box_reg: 0.5291  loss_rpn_cls: 0.00519  loss_rpn_loc: 0.04626  time: 0.5208  data_time: 0.3302  lr: 0.00017982  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:53:18 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 739  total_loss: 0.7669  loss_cls: 0.3341  loss_box_reg: 0.3826  loss_rpn_cls: 0.009462  loss_rpn_loc: 0.02951  time: 0.5209  data_time: 0.3414  lr: 0.00018482  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:53:28 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 759  total_loss: 0.7914  loss_cls: 0.3551  loss_box_reg: 0.3767  loss_rpn_cls: 0.00434  loss_rpn_loc: 0.02088  time: 0.5213  data_time: 0.3499  lr: 0.00018981  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:53:39 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 779  total_loss: 0.6767  loss_cls: 0.3121  loss_box_reg: 0.3671  loss_rpn_cls: 0.002134  loss_rpn_loc: 0.01778  time: 0.5215  data_time: 0.3465  lr: 0.00019481  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:53:49 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 799  total_loss: 0.9036  loss_cls: 0.4073  loss_box_reg: 0.4001  loss_rpn_cls: 0.005592  loss_rpn_loc: 0.0275  time: 0.5212  data_time: 0.3205  lr: 0.0001998  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:54:00 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 819  total_loss: 0.8016  loss_cls: 0.3419  loss_box_reg: 0.3476  loss_rpn_cls: 0.005628  loss_rpn_loc: 0.03057  time: 0.5212  data_time: 0.3352  lr: 0.0002048  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:54:10 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 839  total_loss: 0.62  loss_cls: 0.2673  loss_box_reg: 0.3149  loss_rpn_cls: 0.002545  loss_rpn_loc: 0.02112  time: 0.5211  data_time: 0.3348  lr: 0.00020979  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:54:21 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 859  total_loss: 0.7403  loss_cls: 0.3791  loss_box_reg: 0.3562  loss_rpn_cls: 0.005112  loss_rpn_loc: 0.02947  time: 0.5211  data_time: 0.3372  lr: 0.00021479  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:54:31 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 879  total_loss: 0.6592  loss_cls: 0.3118  loss_box_reg: 0.3278  loss_rpn_cls: 0.002409  loss_rpn_loc: 0.02279  time: 0.5209  data_time: 0.3306  lr: 0.00021978  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:54:41 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 899  total_loss: 0.7234  loss_cls: 0.3444  loss_box_reg: 0.3271  loss_rpn_cls: 0.007265  loss_rpn_loc: 0.02352  time: 0.5207  data_time: 0.3396  lr: 0.00022478  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:54:51 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 919  total_loss: 0.6219  loss_cls: 0.2897  loss_box_reg: 0.2832  loss_rpn_cls: 0.002367  loss_rpn_loc: 0.0236  time: 0.5205  data_time: 0.3391  lr: 0.00022977  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:55:02 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 939  total_loss: 0.4785  loss_cls: 0.2283  loss_box_reg: 0.2433  loss_rpn_cls: 0.001433  loss_rpn_loc: 0.01731  time: 0.5204  data_time: 0.3509  lr: 0.00023477  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:55:13 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 959  total_loss: 0.6125  loss_cls: 0.2732  loss_box_reg: 0.2608  loss_rpn_cls: 0.003719  loss_rpn_loc: 0.02067  time: 0.5208  data_time: 0.3702  lr: 0.00023976  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:55:23 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 979  total_loss: 0.6981  loss_cls: 0.3116  loss_box_reg: 0.3155  loss_rpn_cls: 0.004963  loss_rpn_loc: 0.01871  time: 0.5206  data_time: 0.3433  lr: 0.00024476  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:55:34 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.664  loss_cls: 0.289  loss_box_reg: 0.3002  loss_rpn_cls: 0.005825  loss_rpn_loc: 0.02253  time: 0.5204  data_time: 0.3375  lr: 0.00024975  max_mem: 4394M\n",
      "\u001b[32m[11/30 15:55:34 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:08:39 (0.5204 s / it)\n",
      "\u001b[32m[11/30 15:55:34 d2.engine.hooks]: \u001b[0mTotal training time: 0:08:41 (0:00:02 on hooks)\n"
     ]
    }
   ],
   "source": [
    "#THIS WILL START THE TRAINER, which can be time consuming\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: kill: (16886) - No such process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 81380."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "!kill 16886\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config for test mode\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = detect_thresh # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"test\", )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/30 15:59:29 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[11/30 15:59:29 d2.data.datasets.coco]: \u001b[0mLoaded 48 images in COCO format from /data/collembola_ai/test/test.json\n"
     ]
    }
   ],
   "source": [
    "#prepare test dataset\n",
    "dataset_dicts_test = DatasetCatalog.get(\"test\")\n",
    "dataset_metadata_test = MetadataCatalog.get(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotate all pictures of testset1 and testset2 with the predictions of the trained model\n",
    "os.makedirs(output_dir_imgs, exist_ok=True)\n",
    "output_testset1 = os.path.join(output_dir_imgs, \"testset1\")\n",
    "os.makedirs(output_testset1, exist_ok=True)\n",
    "output_testset2 = os.path.join(output_dir_imgs, \"testset2\")\n",
    "os.makedirs(output_testset2, exist_ok=True)\n",
    "\n",
    "i = 0\n",
    "for d in dataset_dicts_test:\n",
    "    #create variable with output name\n",
    "    output_name = output_testset1 + \"/annotated_\" + str(i) + \".jpg\"\n",
    "    #load image\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    #make prediction\n",
    "    outputs = predictor(img)\n",
    "    #draw prediction\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=dataset_metadata_test, scale=1.)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    vis = visualizer.draw_instance_predictions(instances)\n",
    "    result = vis.get_image()[:, :, ::-1]\n",
    "    #write image\n",
    "    write_res = cv2.imwrite(output_name, result)\n",
    "    i += 1\n",
    "    break\n",
    "\n",
    "for i in os.listdir(os.path.join(working_dir,test_set2)):\n",
    "    if \".jpg\" in i:\n",
    "        file_path = os.path.join(working_dir, test_set2, i)\n",
    "        im = cv2.imread(file_path)\n",
    "        outputs = predictor(im)\n",
    "        v = Visualizer(im[:, :, ::-1], metadata=dataset_metadata, scale=1.)\n",
    "        instances = outputs[\"instances\"].to(\"cpu\")\n",
    "        v = v.draw_instance_predictions(instances)\n",
    "        result = v.get_image()[:, :, ::-1]\n",
    "        output_name = output_testset2 + \"/annotated_\" + str(i) + \".jpg\"\n",
    "        write_res = cv2.imwrite(output_name, result)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input /path/to/input\n",
    "input_single_img=\"/data/collembola_ai/mix_plate4.jpg\"\n",
    "#Output (just name, will be saved in $output_dir_imgs/single_images)\n",
    "output_single_name=\"test.jpg\"\n",
    "\n",
    "#single image prediction\n",
    "#define outputname / path\n",
    "single_img_output=os.path.join(output_dir_imgs,\"single_images\")\n",
    "os.makedirs(single_img_output, exist_ok=True)\n",
    "\n",
    "output_name = os.path.join(single_img_output,output_single_name)\n",
    "#load an image\n",
    "img = cv2.imread(input_single_img)\n",
    "outputs = predictor(img)\n",
    "visualizer = Visualizer(img[:, :, ::-1], metadata=dataset_metadata_test, scale=1.)\n",
    "instances = outputs[\"instances\"].to(\"cpu\")\n",
    "vis = visualizer.draw_instance_predictions(instances)\n",
    "result = vis.get_image()[:, :, ::-1]\n",
    "write_res = cv2.imwrite(output_name, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/30 16:06:24 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/30 16:06:24 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[11/30 16:06:24 d2.data.datasets.coco]: \u001b[0mLoaded 48 images in COCO format from /data/collembola_ai/test/test.json\n",
      "\u001b[32m[11/30 16:06:24 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
      "| ceratophyse.. | 9            |   desoria    | 36           | deuterosmin.. | 58           |\n",
      "|   folsomia    | 55           | megalothorax | 23           | pseudosinella | 25           |\n",
      "|    sinella    | 17           | sminthurides | 52           |   species01   | 58           |\n",
      "|  sphaeridia   | 52           |              |              |               |              |\n",
      "|     total     | 385          |              |              |               |              |\u001b[0m\n",
      "\u001b[32m[11/30 16:06:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/30 16:06:24 d2.data.common]: \u001b[0mSerializing 48 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/30 16:06:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
      "\u001b[32m[11/30 16:06:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 48 images\n",
      "\u001b[32m[11/30 16:06:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/48. 0.0701 s / img. ETA=0:00:09\n",
      "\u001b[32m[11/30 16:06:33 d2.evaluation.evaluator]: \u001b[0mInference done 31/48. 0.0710 s / img. ETA=0:00:04\n",
      "\u001b[32m[11/30 16:06:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.310284 (0.263030 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 16:06:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.072188 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/30 16:06:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/30 16:06:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /data/collembola_ai/output/1000/coco_instances_results.json\n",
      "\u001b[32m[11/30 16:06:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.543\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\n",
      "\u001b[32m[11/30 16:06:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 48.890 | 76.941 | 54.254 |  nan  | 65.000 | 48.810 |\n",
      "\u001b[32m[11/30 16:06:37 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[11/30 16:06:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category       | AP     | category     | AP     | category          | AP     |\n",
      "|:---------------|:-------|:-------------|:-------|:------------------|:-------|\n",
      "| ceratophysella | 42.114 | desoria      | 57.813 | deuterosminthurus | 63.194 |\n",
      "| folsomia       | 34.024 | megalothorax | 34.647 | pseudosinella     | 80.434 |\n",
      "| sinella        | 48.520 | sminthurides | 50.542 | species01         | 39.794 |\n",
      "| sphaeridia     | 37.819 |              |        |                   |        |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 48.89002297980867,\n",
       "               'AP50': 76.94115935671701,\n",
       "               'AP75': 54.2543081817539,\n",
       "               'APs': nan,\n",
       "               'APm': 65.0,\n",
       "               'APl': 48.81011232758113,\n",
       "               'AP-ceratophysella': 42.113586358635864,\n",
       "               'AP-desoria': 57.813182631438664,\n",
       "               'AP-deuterosminthurus': 63.19432856586978,\n",
       "               'AP-folsomia': 34.02350778229443,\n",
       "               'AP-megalothorax': 34.64653335450399,\n",
       "               'AP-pseudosinella': 80.43384832988794,\n",
       "               'AP-sinella': 48.52014998251747,\n",
       "               'AP-sminthurides': 50.5421676086563,\n",
       "               'AP-species01': 39.793645945563384,\n",
       "               'AP-sphaeridia': 37.81927923871891})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IN-BUILD MODEL EVALUATION\n",
    "#I did not found this really useful since the evaluation takes the accurate position strongly into account, something what we do not care as much about...\n",
    "evaluator = COCOEvaluator(\"test\", cfg, False, output_dir=output_dir_imgs)\n",
    "val_loader = build_detection_test_loader(cfg, \"test\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stas ist ein Noobmaster.\n"
     ]
    }
   ],
   "source": [
    "print(\"Stas ist ein Noobmaster.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
